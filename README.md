# AI COSS AutoCar3G Autonomous Driving Robot â€” Winner ğŸ†

**Winner solution** for the **AI COSS Autonomous Driving Robot Competition**,  
focusing on real-time autonomous driving and reward-maximizing decision-making  
under embedded system constraints.

---

## ğŸ Overview

This project implements an **end-to-end autonomous driving robot system** developed for the  
**AI COSS Autonomous Driving Competition**, where the objective was to **maximize total reward
within a limited time** while maintaining stable autonomous driving.

The system combines:
- **Camera-based line tracing** for continuous driving
- **Decision-making algorithms** to select optimal paths at intersections
- **Object detection** to identify reward signals

All components were deployed and validated on a **Jetson Nanoâ€“based AutoCar3G platform**,  
reflecting real-world constraints such as limited compute resources and real-time inference.

ğŸ† **Final Result: Winner (1st Place, External Competition)**

---

## ğŸ§  Core Problem

Beyond basic line following, the key challenge was **decision-making under uncertainty**:

- Which path (left/right) yields higher expected reward?
- How to balance exploration and exploitation in a short time window?
- How to integrate perception, control, and decision logic on embedded hardware?

To address this, we designed a system that **explicitly separates perception, control, and decision layers**, enabling flexible and robust behavior during competition runs.

---

## âš™ï¸ System Architecture
Camera Input
â†“
CNN-based Line Tracing (Steering Control)
â†“
Intersection Detection
â†“
Two-Armed Bandit Decision Module (Left / Right)
â†“
YOLO Object Detection (Reward Signal)
â†“
Reward Update & Policy Adjustment


- **Jetson Nano** performs real-time control and inference
- **YOLO-based detection** provides sparse but high-impact reward signals
- Cooldown logic prevents duplicate reward counting within a single lap

---

## âœ¨ Key Features

- ğŸš— **CNN-based Line Tracing**
  - Lightweight model optimized for Jetson Nano
  - Stable multi-lap autonomous driving without collisions

- ğŸ¯ **Two-Armed Bandit Decision Making**
  - UCB-based and ensemble policies
  - Adaptive path selection based on accumulated rewards

- ğŸ‘ï¸ **YOLO-based Object Detection**
  - Detects reward objects (green signals)
  - Serves as reinforcement feedback rather than dense supervision

- ğŸ”— **Real-World System Integration**
  - Deployed on AutoCar3G platform
  - Designed under real-time and hardware constraints

---

## ğŸ›  Tech Stack

- **Language**: Python
- **Embedded Platform**: NVIDIA Jetson Nano
- **Deep Learning**: CNN, YOLOv8
- **Decision Algorithms**: Two-Armed Bandit (UCB, Ensemble Policy)
- **Frameworks**: PyTorch / Keras, OpenCV

---

## ğŸ“Š Results

- Stable autonomous driving across continuous laps
- Effective reward maximization through adaptive decision-making
- Robust performance in a real competition environment
- ğŸ† **Winner of AI COSS Autonomous Driving Robot Competition**

---

## ğŸ“„ Documentation

Detailed project documentation, experimental analysis, and the official competition report are available on Notion:

ğŸ‘‰ https://www.notion.so/AI-COSS-2dd16f83064c813ebde2cc93412979f2

---

## ğŸ‘¤ Author

- **Affiliation**: Seoul National University of Science and Technology (SeoulTech)
- **Role**: Autonomous Driving, Decision Algorithms, System Integration



